{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#最大表示列数の指定（ここでは50列を指定）\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./csv/horse-2008.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e69ba25436ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrace_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./csv/race-2008.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhorse_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./csv/horse-2008.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2009\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrace_tmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./csv/race-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhorse_tmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./csv/horse-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./csv/horse-2008.csv' does not exist"
     ]
    }
   ],
   "source": [
    "race_df = pd.read_csv(\"./csv/race-2008.csv\", sep=\",\")\n",
    "horse_df = pd.read_csv(\"./csv/horse-2008.csv\", sep=\",\")\n",
    "for year in range(2009, 2019):\n",
    "    race_tmp_df = pd.read_csv(\"./csv/race-\"+str(year)+\".csv\", sep=\",\")\n",
    "    horse_tmp_df = pd.read_csv(\"./csv/horse-\"+str(year)+\".csv\", sep=\",\")\n",
    "    race_df = pd.concat([race_df, race_tmp_df], axis=0)\n",
    "    horse_df = pd.concat([horse_df, horse_tmp_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 元データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_id単位で重複したデータが存在しないか確認\n",
    "print(len(race_df) == len(race_df['race_id'].unique()))\n",
    "print(race_df.shape)\n",
    "race_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出走馬数の確認\n",
    "race_df[\"total_horse_number\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(horse_df.shape)\n",
    "horse_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raceデータの整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race_id\n",
    "そのままでOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一応確認\n",
    "race_df[\"race_id\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race_round\n",
    "余分な空白とRを取り除く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"race_round\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['race_round'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['race_round'] = race_df['race_round'].str.strip('R \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['race_round'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['race_round'] = race_df['race_round'].astype(int)\n",
    "race_df[\"race_round\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race_title\n",
    "いらないので削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# もともとのカラムは不要なので削除\n",
    "race_df.drop(['race_title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race_course\n",
    "「ダ右1200m」などであれば、ダート・右回り・1200に分割して、それぞれ別のカラムにする。\n",
    "\n",
    "新たに4つのカラムを追加\n",
    "- 障害コースか？\n",
    "- 地面のタイプは何か？\n",
    "- 右回り・左回り・直線か？\n",
    "- 距離は？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"race_course\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規表現で取得\n",
    "\n",
    "# 障害か、地面のタイプは何か、左か、右か、直線か、\n",
    "obstacle = race_df[\"race_course\"].str.extract('(障)', expand=True)\n",
    "ground_type = race_df[\"race_course\"].str.extract('(ダ|芝)', expand=True)\n",
    "is_left_right_straight = race_df[\"race_course\"].str.extract('(左|右|直線)', expand=True)\n",
    "distance = race_df[\"race_course\"].str.extract('(\\d+)m', expand=True)\n",
    "\n",
    "obstacle.columns ={\"is_obstacle\"}\n",
    "ground_type.columns ={\"ground_type\"}\n",
    "is_left_right_straight.columns = {\"is_left_right_straight\"}\n",
    "distance.columns = {\"distance\"}\n",
    "\n",
    "race_df = pd.concat([race_df, obstacle], axis=1)\n",
    "race_df = pd.concat([race_df, ground_type], axis=1)\n",
    "race_df = pd.concat([race_df, is_left_right_straight], axis=1)\n",
    "race_df = pd.concat([race_df, distance], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'is_obstacle' 列の '障芝' を1に置き換え、Nanに0埋め\n",
    "race_df['is_obstacle'] = race_df['is_obstacle'].replace('障', 1)\n",
    "race_df.fillna(value={'is_obstacle': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"is_obstacle:\", race_df[\"is_obstacle\"].unique())\n",
    "print(\"ground_type:\", race_df[\"ground_type\"].unique())\n",
    "print(\"is_left_right_straight:\", race_df[\"is_left_right_straight\"].unique())\n",
    "print(\"distance isnull sum:\", race_df[\"distance\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# もともとのカラムは不要なので削除\n",
    "race_df.drop(['race_course'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"distance\"] = race_df[\"distance\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather\n",
    "そのままone_hotエンコーディングしてデータを食わせても良さそうだが...\n",
    "\n",
    "余分な文字列を取り除く。\n",
    "\n",
    "また、少雨よりも雨が強いはず、小雪よりも雪が強いはず。これらの単純な雨量は別のデータを取ってこないと分からないが、大小関係は情報として入れられるはず。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"weather\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['weather'] = race_df['weather'].str.strip('天候 :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"weather\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_rain = race_df[\"weather\"].str.extract('(小雨|雨)', expand=True)\n",
    "weather_snow = race_df[\"weather\"].str.extract('(小雪|雪)', expand=True)\n",
    "weather_rain.columns ={\"weather_rain\"}\n",
    "weather_snow.columns ={\"weather_snow\"}\n",
    "race_df = pd.concat([race_df, weather_rain], axis=1)\n",
    "race_df = pd.concat([race_df, weather_snow], axis=1)\n",
    "\n",
    "race_df.fillna(value={'weather_rain': 0}, inplace=True)\n",
    "race_df['weather_rain'] = race_df['weather_rain'].replace('小雨', 1)\n",
    "race_df['weather_rain'] = race_df['weather_rain'].replace('雨', 2)\n",
    "race_df.fillna(value={'weather_snow': 0}, inplace=True)\n",
    "race_df['weather_snow'] = race_df['weather_snow'].replace('小雪', 1)\n",
    "race_df['weather_snow'] = race_df['weather_snow'].replace('雪', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"weather_rain:\", race_df[\"weather_rain\"].value_counts())\n",
    "print(\"weather_snow:\", race_df[\"weather_snow\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ground_status\n",
    "芝かダートかは既に別カラムにあるので、状態を見る。\n",
    "大小関係があるので数値として。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"ground_status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['ground_status'] = race_df['ground_status'].replace('.*(稍重).*', 4,regex=True)\n",
    "race_df['ground_status'] = race_df['ground_status'].replace('.*(重).*', 3,regex=True)\n",
    "race_df['ground_status'] = race_df['ground_status'].replace('.*(不良).*', 2,regex=True)\n",
    "race_df['ground_status'] = race_df['ground_status'].replace('.*(良).*', 1,regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ground_status:\", race_df[\"ground_status\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time と dateをあわせてdatetimeに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"time\"] = race_df[\"time\"].str.replace('発走 : (\\d\\d):(\\d\\d)(.|\\n)*', r'\\1時\\2分')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"date\"] = race_df[\"date\"] + race_df[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"date\"] = pd.to_datetime(race_df['date'], format='%Y年%m月%d日%H時%M分')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# もともとのtimeは不要なので削除\n",
    "race_df.drop(['time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(race_df[\"date\"].dtype)\n",
    "print(\"date isnull sum:\", race_df[\"date\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where_racecourse\n",
    "例:1回小倉3日目 の中から小倉を取り出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"where_racecourse\"] = race_df[\"where_racecourse\"].str.replace('\\d*回(..)\\d*日目', r'\\1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "race_df[\"where_racecourse\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  馬の数や順位\n",
    "- total_horse_number                 int64\n",
    "- frame_number_first                 int64\n",
    "- horse_number_first                 int64\n",
    "- frame_number_second                int64\n",
    "- horse_number_second                int64\n",
    "- frame_number_third                 int64\n",
    "- horse_number_third                 int64\n",
    "\n",
    "これらはそのままでOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オッズから余分な「,」を除く\n",
    "- tansyo                            object\n",
    "- hukuren_first                     object\n",
    "- hukuren_second                    object\n",
    "- hukuren_third                     object\n",
    "- renhuku3                          object\n",
    "- rentan3                           object\n",
    "\n",
    "数値と文字列が混在しているので面倒\n",
    "```\n",
    "race_df['tansyo'] = race_df['tansyo'].str.strip(',')\n",
    "```\n",
    "などとしてもだめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['tansyo'] = race_df['tansyo'].apply(lambda x: int(x.replace(\",\", \"\")) if type(x) is str else int(x))\n",
    "race_df['hukuren_first'] = race_df['hukuren_first'].apply(lambda x: int(x.replace(\",\", \"\")) if type(x) is str else int(x))\n",
    "race_df['hukuren_second'] = race_df['hukuren_second'].apply(lambda x: int(x.replace(\",\", \"\")) if type(x) is str else int(x))\n",
    "race_df['hukuren_third'] = race_df['hukuren_third'].apply(lambda x: int(x.replace(\",\", \"\")) if type(x) is str else int(x))\n",
    "race_df['renhuku3'] = race_df['renhuku3'].apply(lambda x: int(x.replace(\",\", \"\")) if type(x) is str else int(x))\n",
    "race_df['rentan3'] = race_df['rentan3'].apply(lambda x: int(x.replace(\",\", \"\")) if type(x) is str else int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "race_df['race_id'] = race_df['race_id'].astype(str)\n",
    "#race_df['race_title'] = race_df['race_title'].astype(str)\n",
    "print('dataframeの各列のデータ型を確認==>\\n', race_df.dtypes)\n",
    "\n",
    "\n",
    "race_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## race dataの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df.to_csv(\"csv/cleaned_race_data.csv\", index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## horse data の整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(horse_df.shape)\n",
    "print(horse_df.dtypes)\n",
    "horse_df['race_id'] = horse_df['race_id'].astype(str)\n",
    "horse_df['horse_id'] = horse_df['horse_id'].astype(str)\n",
    "horse_df['tamer_id'] = horse_df['tamer_id'].astype(str)\n",
    "horse_df['owner_id'] = horse_df['owner_id'].astype(str)\n",
    "horse_df['rider_id'] = horse_df['rider_id'].astype(str)\n",
    "\n",
    "horse_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 何かとデータ分析で便利なので、レース日時情報をmerge\n",
    "race_tmp_df = race_df[[\"race_id\", \"date\"]]\n",
    "horse_df = pd.merge(horse_df, race_tmp_df, on='race_id')\n",
    "horse_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使わなさそうな情報を削除\n",
    "- time_value, tame_time(プレミアム会員向けの情報)\n",
    "- goal_time_dif(自分で作成する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df.drop(['time_value'], axis=1, inplace=True)\n",
    "horse_df.drop(['goal_time_dif'], axis=1, inplace=True)\n",
    "horse_df.drop(['tame_time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race_id\n",
    "そのままでOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank\n",
    "> - 降着・・・\t「その走行妨害がなければ被害馬が加害馬に先着していた」と判断した場合、加害馬は被害馬の後ろに降着となります。\n",
    "> - 失格・・・\t「極めて悪質で他の騎手や馬に対する危険な行為によって、競走に重大な支障を生じさせた」と判断した場合、加害馬は失格となります。\n",
    "\n",
    "> 注記：被害馬が落馬や疾病発症等により競走を中止した場合には、上記の「失格」に該当しない限り着順は到達順位のとおり確定します。\n",
    "\n",
    "- 中(中止。オッズはある。ゴールに到達しない...？)         2752\n",
    "- 取(取り消し。オッズもない。そもそも参加していない．．．？)         1069\n",
    "- 除(除名？。オッズもない。そもそも参加していない．．．？)          889\n",
    "\n",
    "は結構な頻度で起きる。他の異常値は少ないので削除するかまとめる...？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 降格は降格フラグに分割、順位そのまま入れておく\n",
    "- 取・除はそもそも参加していないので削除\n",
    "- 失は順位が全く当てにならないので情報を削除\n",
    "- 中は最後まで到達していないが参加はしている。ひとまず20位にしておく。goal_timeが無いので、大きめに取る必要がある。\n",
    "- 12(再)は12で最後の模様。そのまま12にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "horse_df[horse_df['rank'] =='中'].sort_values('date').head(2)\n",
    "horse_df[horse_df['rank'] =='取'].sort_values('date').head(2)\n",
    "horse_df[horse_df['rank'] =='除'].sort_values('date').head(2)\n",
    "horse_df[horse_df['rank'] =='16(降)'].sort_values('date').head(2)\n",
    "horse_df[horse_df['rank'] =='12(再)'].sort_values('date').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 降格を別へ\n",
    "is_down = horse_df[\"rank\"].str.extract('(\\(降\\))', expand=True)\n",
    "is_down.columns ={\"is_down\"}\n",
    "horse_df = pd.concat([horse_df, is_down], axis=1)\n",
    "\n",
    "horse_df.fillna(value={'is_down': 0}, inplace=True)\n",
    "horse_df['is_down'] = horse_df['is_down'].replace('(降)', 1)\n",
    "\n",
    "## 余分な文字を削除\n",
    "horse_df['rank'] = horse_df['rank'].apply(lambda x: x.replace(\"(降)\", \"\"))\n",
    "horse_df['rank'] = horse_df['rank'].apply(lambda x: x.replace(\"(再)\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"- 取・除はそもそも参加していないので削除\n",
    "- 失は順位が全く当てにならないので情報を削除\n",
    "- 中は最後まで到達していないが参加はしている。ひとまず20位にしておく\"\"\"\n",
    "\n",
    "horse_df = horse_df[(horse_df['rank'] != \"取\") & (horse_df['rank'] != \"除\") & (horse_df['rank'] != \"失\")]\n",
    "horse_df['rank'] = pd.DataFrame(horse_df['rank'].mask(horse_df['rank'] == \"中\", 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "horse_df[\"rank\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 姓と年齢をsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df['sex_and_age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性別を別へ\n",
    "\"\"\"\n",
    "sex = horse_df[\"sex_and_age\"].str.extract('(牝|牡|セ)', expand=True)\n",
    "sex.columns ={\"sex\"}\n",
    "horse_df = pd.concat([horse_df, sex], axis=1)\n",
    "\n",
    "horse_df.fillna(value={'sex': 0}, inplace=True)\n",
    "horse_df['sex'] = horse_df['sex'].replace('牝', 1)\n",
    "horse_df['sex'] = horse_df['sex'].replace('牡', 2)\n",
    "horse_df['sex'] = horse_df['sex'].replace('セ', 3)\n",
    "## 余分な文字を削除\n",
    "horse_df['sex_and_age'] = horse_df['sex_and_age'].str.strip(\"牝牡セ\")\n",
    "horse_df['sex_and_age'] = horse_df['sex_and_age'].astype(int)\n",
    "\"\"\"\n",
    "\n",
    "is_senba = horse_df[\"sex_and_age\"].str.extract('(セ)', expand=True)\n",
    "is_senba.columns ={\"is_senba\"}\n",
    "horse_df = pd.concat([horse_df, is_senba], axis=1)\n",
    "\n",
    "is_mesu = horse_df[\"sex_and_age\"].str.extract('(牝)', expand=True)\n",
    "is_mesu.columns ={\"is_mesu\"}\n",
    "horse_df = pd.concat([horse_df, is_mesu], axis=1)\n",
    "\n",
    "is_osu = horse_df[\"sex_and_age\"].str.extract('(牡)', expand=True)\n",
    "is_osu.columns ={\"is_osu\"}\n",
    "horse_df = pd.concat([horse_df, is_osu], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df.fillna(value={'is_osu': 0}, inplace=True)\n",
    "horse_df['is_osu'] = horse_df['is_osu'].replace('牡', 1)\n",
    "horse_df.fillna(value={'is_mesu': 0}, inplace=True)\n",
    "horse_df['is_mesu'] = horse_df['is_mesu'].replace('牝', 1)\n",
    "horse_df.fillna(value={'is_senba': 0}, inplace=True)\n",
    "horse_df['is_senba'] = horse_df['is_senba'].replace('セ', 1)\n",
    "## 余分な文字を削除\n",
    "horse_df['sex_and_age'] = horse_df['sex_and_age'].str.strip(\"牝牡セ\")\n",
    "horse_df['sex_and_age'] = horse_df['sex_and_age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df = horse_df.rename(columns={'sex_and_age': 'age'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## goal_timeをtimedelta型にしてから秒に(last_timeも)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nullになるのは、レースで「中」になった馬\n",
    "print(horse_df['goal_time'].isnull().sum())\n",
    "print(horse_df['last_time'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df['goal_time'] = pd.to_datetime(horse_df['goal_time'], format='%M:%S.%f') - pd.to_datetime('00:00.0', format='%M:%S.%f')\n",
    "horse_df['goal_time'] = horse_df['goal_time'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値を最大値で埋める\n",
    "horse_df.fillna(value={'goal_time': horse_df['goal_time'].max()}, inplace=True)\n",
    "horse_df.fillna(value={'last_time': horse_df['last_time'].max()}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### goal_timeとレース距離から、平均速度を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レース距離情報をmerge\n",
    "race_tmp_df = race_df[[\"race_id\", \"distance\"]]\n",
    "horse_df = pd.merge(horse_df, race_tmp_df, on='race_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df[\"distance\"] = horse_df[\"distance\"].astype(int)\n",
    "horse_df[\"avg_velocity\"] = horse_df[\"distance\"]/horse_df[\"goal_time\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### half_way_rank\n",
    "splitして平均値を保持する（レースによってまちまちなので）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "horse_df[\"half_way_rank\"] = horse_df[\"half_way_rank\"].apply(lambda x: mean([float(n) for n in (x.split(\"-\"))]) if type(x) is str else float(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df[horse_df[\"rank\"] == 20] = horse_df[horse_df[\"rank\"] == 20].fillna({'half_way_rank': 20})\n",
    "horse_df[\"half_way_rank\"] = horse_df[\"half_way_rank\"].fillna(horse_df['half_way_rank'].mean())\n",
    "horse_df[\"half_way_rank\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df[\"half_way_rank\"] = horse_df[\"half_way_rank\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### horse_weight と diff の分離\n",
    "「計不」は平均で穴埋め"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_weight_dif = horse_df[\"horse_weight\"].str.extract('\\(([-|+]?\\d*)\\)', expand=True)\n",
    "horse_weight_dif.columns ={\"horse_weight_dif\"}\n",
    "\n",
    "horse_df = pd.concat([horse_df, horse_weight_dif], axis=1)\n",
    "\n",
    "horse_df['horse_weight'] = horse_df['horse_weight'].replace('\\(([-|+]?\\d*)\\)', '', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df['horse_weight'] = horse_df['horse_weight'].replace('計不', np.nan)\n",
    "horse_df['horse_weight'] = horse_df['horse_weight'].astype(float)\n",
    "horse_df['horse_weight_dif'] = horse_df['horse_weight_dif'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計不 の horse_idを探し、馬ごとの平均値で穴埋め\n",
    "no_records = horse_df[horse_df['horse_weight'].isnull()]['horse_id']\n",
    "for no_record_id in no_records:\n",
    "    horse_df.loc[(horse_df['horse_id'] == no_record_id)&(horse_df['horse_weight'].isnull()), 'horse_weight'] = horse_df[horse_df['horse_id'] == no_record_id]['horse_weight'].mean() \n",
    "    horse_df.loc[(horse_df['horse_id'] == no_record_id)&(horse_df['horse_weight_dif'].isnull()), 'horse_weight_dif'] = 0 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### burden_weight, horse_weight の比率を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df['burden_weight_rate'] = horse_df['burden_weight']/horse_df['horse_weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### last_time\n",
    "とりあえず放置するが、外れ値の扱いを考えたほうが良さそう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df.plot(kind='hist', y='last_time' , bins=50, figsize=(16,4), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df[horse_df['last_time']<20]['race_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[(race_df['race_id']=='200808010804') | (race_df['race_id']=='200806010208') | (race_df['race_id']=='200806010304')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df['odds']= horse_df['odds'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### horse dataの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(horse_df.dtypes)\n",
    "horse_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df.to_csv(\"csv/cleaned_horse_data.csv\", index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
